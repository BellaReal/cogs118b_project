{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Insert title here]\n",
    "\n",
    "# Group Members\n",
    "\n",
    "- Hunter Flores\n",
    "- Isabella Real\n",
    "- Harvey Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Given the COVID-19 data dataset and population statistics of countries around the world, the objective is to cluster based on confirmed cases, confirmed deaths, excess mortality, hospital & ICU, policy responses, reproduction rate, tests & positivity, vaccinations, and country statistics, with the goal of finding the relationship between countries and time. The data used represent 67 variables relating to COVID-19, and 376884 observations, where each of them represent one location and date. We will clean them up so that they can be directly used for our purpose, including renaming and clearing up the redundant columns and indices. Then, we will use K-Means and GMM to cluster the data in order to determine relationships between countries, and see how variables interact over time. Dimensional reduction may also be applied to those models, and potentially an evaluation on influence of the factors that might decrease the number of cases. As we are choosing K-Means and GMM as our tools, we will use silhouette score and distortion measure to determine the optional number of clusters.\n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The pandemic has led to significant morbidity and mortality, overwhelmed healthcare systems, disrupted global supply chains, and caused widespread economic and social upheaval, while posing a huge challenge to education which is closely related to us students<a name=\"daniel\"></a>[<sup>[1]</sup>](#daniel).\n",
    "Thus, there has been a great public interest in studying the pandemic, covering its epidemiology, transmission dynamics, clinical manifestations, socio-economic effects, mental health impacts, and the effectiveness of interventions, including non-pharmaceutical interventions (NPIs) and vaccines<a name=\"who\"></a>[<sup>[2]</sup>](#who).\n",
    "\n",
    "Prior work involves lots of dimensions of studies. Previous studies have applied clustering algorithms to COVID-19 data to group countries or regions by similar epidemic characteristics or responses.<a name=\"kucharski\"></a>[<sup>[3]</sup>](#kucharski)\n",
    "Research has also used mathematical modeling to help estimate outbreak dynamics and provide decision guidelines for successful outbreak control.<a name=\"peirlinck\"></a>[<sup>[4]</sup>](#peirlinck)\n",
    "Therefore, based on all these prior studies done on COVID-19, we are interested in looking at all the aspects of statistics used in evaluation, which can be clustered into different categories. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Given the COVID-19 data dataset and population statistics of countries around the world, the objective is to cluster based on confirmed cases, confirmed deaths, excess mortality, hospital & ICU, policy responses, reproduction rate, tests & positivity, vaccinations, and country statistics, with the goal of finding the relationship between countries and time. What variables affect the number of cases the most? How do the variables change over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "* https://github.com/owid/covid-19-data/tree/master/public/data\n",
    "* This dataset contains a total of 376884 rows (observations) × 67 columns (variables)\n",
    "* Each observation consists of information from a given date about the number of cases, deaths, vaccinations, and other data about the population like the number of female and male smokers, diabetes rates, and other statistics.\n",
    "* Some critical variables are:\n",
    "  - “total_cases” -> total number of confirmed cases of covid-19 (includes probable cases)\n",
    "  - “new_cases” -> number of new confirmed cases in a day (includes probable cases)\n",
    "  - “new_cases_smoothed” -> new_cases smoothed over 7 days\n",
    "  - “total_deaths” -> total number of deaths resulting from covid-19 including probable deaths\n",
    "  - “new_deaths” -> number of deaths daily caused by covid-19 in a day\n",
    "  - “new_deaths_smoothed” -> new_deaths smoothed over 7 days\n",
    "  - “excess_mortality” -> difference between predicted number of deaths and actual number of deaths for 2020-2021 by percentage\n",
    "  - “icu_patients” -> number of patients in intensive care units with covid-19 in a day\n",
    "  - “hosp_patients” -> number of patients in hospitals with covid-19 in a day\n",
    "  - “weekly_icu_admissions” -> number of icu patients admitted with covid-19 including patients admitted on recorded date and all 6 days prior\n",
    "  - “weekly_hosp_admissions” -> number of hospital patients admitted with covid-19 including patients admitted on recorded date and all 6 days prior\n",
    "  - “stringency_index” -> value between 0 and 100 measuring strictness of response composed of nine different responses “The nine metrics used to calculate the Stringency Index are: school closures; workplace closures; cancellation of public events; restrictions on public gatherings; closures of public transport; stay-at-home requirements; public information campaigns; restrictions on internal movements; and international travel controls” (https://ourworldindata.org/covid-stringency-index)\n",
    "  - “reproduction_rate” -> estimate of the reproductive rate of covid-19\n",
    "  - “total_tests” -> total number of covid-19 tests taken\n",
    "  - “total_vaccinations” -> total number of covid-19 vaccinations administered\n",
    "  - “location” -> name of country where observation took place\n",
    "  - “date” -> date of observation in year-month-day format\n",
    "  - “diabetes_prevelance” -> percent of the population between 20-79 with diabetes as of 2017\n",
    "  - “male_smokers”/”female_smokers” -> percent of population that smoke (by sex)\n",
    "* A lot of the data is sparse, so we will need to handle the data points that are missing.  In addition to this, a lot of the data is probably redundant (for example the number of handwashing stations, population…) So in order to handle this we propose having two different data frames.  One data frame to represent each country's more or less unchanging statistics over the course of this four year period and another that contains data that changes over time (number of cases, deaths, number of vaccinations…)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our solution includes using t-SNE to reduce dimentionality of our data which are then represented by three timepoints (beginning, middle, and end), and GMM to cluster the data in order to determine possible relationships between countries and/or those between variables. We will use silhoutte scores to visualize and evaluate the effects of different parameters in clustering. We will then judge based on the clustering results to try to determine what variables are most influential in decreasing the number of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "As we are using K-Means and GMM, we will use silhouette score and distortion measure to determine the optional number of clusters. \n",
    "\n",
    "### Silhouette Score\n",
    "Mathematically, Silhouette score is calculated by:\n",
    "$$ \\text{Silhouette Score} = \\frac{b-a}{max(a,b)} $$\n",
    "Where:\n",
    "$a$ is the mean distance between a sample and all other points in the same cluster.\n",
    "$b$ is the mean distance between a sample and all other points in the next nearest cluster.\n",
    "A higher Silhouette Score implies better clustering.\n",
    "\n",
    "### Distortion Measure\n",
    "Distortion measures the compactness of the clusters. It is the sum of squared distances between each data point and the centroid of its assigned cluster. Mathematically, for a dataset with $n$ data points and $k$ clusters, distortion measure is calculated by:\n",
    "$$ \\text{Distortion} = \\sum^n_{i=1} \\sum^k_{j=1} d(x_i, c_j)^2 $$\n",
    "Where $x_i$ is the $i$-th data point and $c_j$ is the centroid of the $j$-th cluster, and $d$ is the distance between $x_i$ and $c_j$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "[OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.]\n",
    "\n",
    "### Limitations\n",
    "\n",
    "[Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?]  \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "Data privacy can be one of the most concerning aspects of the internet to the public nowadays. Although our data is mostly on the country level, and all the data is anonymized, it is still crucial to ensure that personal data cannot be de-anonymized to protect personal information of the public. \n",
    "\n",
    "One other ethical concern is that we, the Machine Learning engineers, are humans, and are also subject to the common logical biases, which may in turn influence our judgment of the study done in the process of evaluating the data and achieving our goal in this project. \n",
    "\n",
    "Another potential impact of this project is the impression it leaves to the public, which can be different to each individual, potentially leading to misuse and misunderstanding of the project in a negative way.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "[Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
